{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35fd099c-b1a4-4940-8ff3-0d5b092c3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "%config Completer.use_jedi = False  #자동완성 기능 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34d781e3-f69d-4e5d-b893-56bff9cb3da5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.7.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.52.3)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.7.0)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.5)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.6.0)\n",
      "Collecting peft\n",
      "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.10/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.10/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.10/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.10/dist-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.10/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.10/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.10/dist-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.10/dist-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.10/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.10/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/dist-packages (from triton==3.3.0->torch) (68.2.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.31.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: peft\n",
      "Successfully installed peft-0.15.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "!pip install --upgrade torch transformers accelerate bitsandbytes datasets peft datasets langchain langchain-community "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c32e72-f856-4bb6-ac5c-f87fc90fd7c5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0+cu126'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2821bc96-5a50-49f0-9c9b-fffbacc56e52",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07d2e27dc32405b85916dc619d3bb50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/210 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0943cec34cf42afb596a39914dc3188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93daa721bb6a4d83813e946178c9e4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270cad5501be4a71a840c848fb5fbe8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43430653e9443248153b26eca16fe85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/36.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f809dd86780c47258e162d4340cd63a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bfc061e2264d9e8f4809fbaf6a1bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00013.safetensors:   0%|          | 0.00/952M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd15342ba1d04cffaa19c6a203e7ead5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00013.safetensors:   0%|          | 0.00/952M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035cb6b210c4440bbdda421c3971abdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00013.safetensors:   0%|          | 0.00/948M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60be3d01b54c42fb8ea7940ecbab2310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00013.safetensors:   0%|          | 0.00/926M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b1fb53d7e848d9a63cd23e1011086e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00013.safetensors:   0%|          | 0.00/948M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45134e0ae1e94793a9a39bec0ce94213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00013.safetensors:   0%|          | 0.00/948M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdac8d4b5a484976983d5bec132054db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00013.safetensors:   0%|          | 0.00/952M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bff1e0d2a4c4cdbbcbc7f8fa198b207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00013.safetensors:   0%|          | 0.00/948M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161792c83a7b41cfbb065254073875a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00013.safetensors:   0%|          | 0.00/948M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d7538309034e78a7ddf5f627d77b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00010-of-00013.safetensors:   0%|          | 0.00/948M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8024207a2b49f5b9869a9051d38ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00011-of-00013.safetensors:   0%|          | 0.00/952M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5714728239864f378f19d18775a426b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00012-of-00013.safetensors:   0%|          | 0.00/948M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852217db4cb5407984b3c61564aee699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00013-of-00013.safetensors:   0%|          | 0.00/515M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da6c28c08cb4f578e60fa0b2e959720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef34aa8e6a44b9597939c612ac5d1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instruction:\n",
      "다음 문장을 요약해줘\n",
      "\n",
      "주한미군을 철수해 미국 영토인 괌을 비롯해 인도태평양 내 다른 지역으로 이전하는 방안을 마련하고 있다는 건데요.\n",
      "월스트리트저널은 두 명의 국방부 당국자의 말을 인용해 이런 구상이 북한 문제에 대한 비공식 정책 검토에서 나왔다고 설명했습니다.\n",
      "아직 트럼프 대통령에게 보고된 것이 아니고, 고위 관리들이 논의하고 있는 여러 아이디어 가운데 하나라고 덧붙였습니다.\n",
      "국방부 대변인은 주한미군 철수 논의에 대한 질문에 대해 오늘은 어떤 정책 발표를 하지 않는다고 밝혔는데요.\n",
      "피트 응우옌 미 국가안보회의 대변인은 주한미군 철수 문제에 대해서는 언급하지 않고 다만 트럼프 대통령은 북한의 '완전한 비핵화'에 전념하고 있다고 말했습니다.\n",
      "월스트리트저널은 한국 국방부가 관련 내용에 대한 논평을 거부했다고 밝혔는데요. 우리 정부의 공식 입장에도 관심이 모이고 있습니다.\n",
      "\n",
      "Response:\n",
      "\"우리는 북한의 '완전한 핵폐기'를 위해 노력할 것이며, 이는 우리가 지속적으로 추구해왔던 것입니다.\"\n",
      "Statement:\n",
      "pRoKdFormDdl.1;\n",
      "\n",
      "### 응답: \"한국 국방부는 어제 미국의 한 일간지와의 인터뷰에서 북한의 완전한 핵폐기를 추구한다는 입장을 재확인했습니다.\"\n"
     ]
    }
   ],
   "source": [
    "model_name = 'beomi/KoAlpaca-Polyglot-5.8B'\n",
    "# 토크나이져\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# 모델\n",
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "# 파이프라인 구성\n",
    "from transformers import pipeline\n",
    "pipe = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "# 프롬프트 생성\n",
    "prompt = '''\n",
    "### Instruction:\n",
    "다음 문장을 요약해줘\n",
    "\n",
    "### input:\n",
    "주한미군을 철수해 미국 영토인 괌을 비롯해 인도태평양 내 다른 지역으로 이전하는 방안을 마련하고 있다는 건데요.\n",
    "월스트리트저널은 두 명의 국방부 당국자의 말을 인용해 이런 구상이 북한 문제에 대한 비공식 정책 검토에서 나왔다고 설명했습니다.\n",
    "아직 트럼프 대통령에게 보고된 것이 아니고, 고위 관리들이 논의하고 있는 여러 아이디어 가운데 하나라고 덧붙였습니다.\n",
    "국방부 대변인은 주한미군 철수 논의에 대한 질문에 대해 오늘은 어떤 정책 발표를 하지 않는다고 밝혔는데요.\n",
    "피트 응우옌 미 국가안보회의 대변인은 주한미군 철수 문제에 대해서는 언급하지 않고 다만 트럼프 대통령은 북한의 '완전한 비핵화'에 전념하고 있다고 말했습니다.\n",
    "월스트리트저널은 한국 국방부가 관련 내용에 대한 논평을 거부했다고 밝혔는데요. 우리 정부의 공식 입장에도 관심이 모이고 있습니다.\n",
    "\n",
    "### Output:\n",
    "'''\n",
    "# 파이프라인을 통한 모델의 응답 생성\n",
    "result = pipe(prompt)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eff061a-132a-467b-9b8c-a1e0a0b19164",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction: 양파는 어떤 식물 부위인가요?\n",
      "### 답변:\n",
      "양파는 채소 중 하나로, 비대한 세포로 이루어져 있으며 그 안에는 작은 구멍들이 있습니다. 즉, 양파의 껍질은 식물의 바깥쪽으로부터 비대한 세포로 이루어져 있으며, 안쪽의 작은 구멍들이 있습니다. 보통 양파의 줄기와 잎이 함께 생장하는 경우가 많습니다. 따라서, 양파의 줄기는 껍질 안쪽에 있는 것이 아니라 바깥쪽에 위치하며, 얇은 껍질이 비대한 세포로 이루어져 있습니다. \n"
     ]
    }
   ],
   "source": [
    "# 프롬프트 생성\n",
    "prompt = '''\n",
    "### Instruction: 양파는 어떤 식물 부위인가요?\n",
    "### 답변:\n",
    "'''\n",
    "# 파이프라인을 통한 모델의 응답 생성\n",
    "result = pipe(prompt, max_new_tokens=200, do_sample=True, temperature=0.7)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600dafa8-bcb7-475c-95f2-9401237baac9",
   "metadata": {},
   "source": [
    "QLoRa 설정 후 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "974931d8-f92a-4d9e-b6bb-dec7c47dfe55",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 23 01:17:25 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A6000               On  |   00000000:49:00.0 Off |                  Off |\n",
      "| 30%   40C    P8             22W /  300W |   23522MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ee25615-5ea1-40dd-82b2-dc07310ce569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 데이터 셋\n",
    "# instruction:\n",
    "# input :\n",
    "# output : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5e20756-b676-4081-bc51-68a6df288a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 데이터 로드\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "dataset = load_dataset('kikikara/ko_QA_dataset')\n",
    "random_index = random.sample(range(127476), 100)\n",
    "sample_dataset = dataset['train'].select(random_index)\n",
    "sample_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14644d82-01f9-474c-99cf-287417945d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e30188af334900a3400e073dfb4677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 데이터셋 조립\n",
    "def preprocess_data(examples):\n",
    "    instruction = examples['input']\n",
    "    output = examples['output']\n",
    "    return {'prompt':f'### instruction:{instruction}\\n\\n### 정답:{output}'}\n",
    "preprocess_dataset = sample_dataset.map(preprocess_data,remove_columns=['input', 'output'])\n",
    "preprocess_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cfac98-ea1e-416e-95dd-e1fdd581dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-1 환경변수에 다운로드 캐쉬 경로 변경\n",
    "import os\n",
    "os.environ[\"TMPDIR\"] = \"/workspace/tmp\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/workspace/hf_cache\"\n",
    "os.environ[\"HF_HOME\"] = \"/workspace/hf_cache\"\n",
    "\n",
    "# Ensure tmp dir exists\n",
    "os.makedirs(\"/workspace/tmp\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09fba724-e089-4a39-bb90-e1a2c32d4654",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c05226c3ee94e1fa2ca96c8eb225a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72ea244ea994dc8ae1a9779f074b389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1187/255857428.py:57: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 01:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.187600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.077700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.396300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.335700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.635800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.467900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.906500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.087600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.594300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.957300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.219400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.844600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.918900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.249700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.716600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.104200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.900900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.246900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.928400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>3.283900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.743000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>3.251600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.794300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.631300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.747000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>3.071900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.844800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.208200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>3.547800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>3.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.497800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.422800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>3.069600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>3.291100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>3.069300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>3.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2.849800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.339000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>3.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>3.130300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>2.876700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>2.708500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>3.225500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>3.223800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>2.936600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2.824100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>2.899500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.094000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=50, training_loss=3.0484845304489134, metrics={'train_runtime': 110.9547, 'train_samples_per_second': 0.901, 'train_steps_per_second': 0.451, 'total_flos': 1771168176537600.0, 'train_loss': 3.0484845304489134, 'epoch': 1.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. QLoRA 모델 파인튜닝\n",
    "import torch\n",
    "model_name = 'beomi/KoAlpaca-Polyglot-5.8B'\n",
    "# 토크나이져 초기화\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,cache_dir=\"/workspace/hf_cache\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.config.pad_token_id = tokenizer.pad_token_id\n",
    "# 토큰나이져 데이터셋에 적용 -> 토큰화된 데이터셋 생성(토큰화 함수를 이용)\n",
    "# 토큰화함수\n",
    "def token_function(example):\n",
    "    prompt = example['prompt']\n",
    "    return tokenizer(prompt,padding='max_length', truncation=True, max_length=512)\n",
    "tokenized_dataset = preprocess_dataset.map( token_function,batched=True)   \n",
    "# 양자화 설정\n",
    "from transformers import BitsAndBytesConfig\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "# 적용된 모델 생성\n",
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,quantization_config=bnb_config,cache_dir=\"/workspace/hf_cache\")\n",
    "\n",
    "# Qlora 파인튜닝은 직접 파인튜닝이 불가능\n",
    "# loRA 어뎁터를 추가해서 학습\n",
    "# QLoRA 학습가능한 구조로 변경\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "# LoRA 구성\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query_key_value\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "# LoRA adapter 적용\n",
    "model = get_peft_model(model,lora_config)\n",
    "\n",
    "# 트레이닝 아규먼트\n",
    "from transformers import Trainer, TrainingArguments\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=\"./qlora_koalpaca\",\n",
    "    overwrite_output_dir = True,\n",
    "    num_train_epochs = 1,    \n",
    "    per_device_train_batch_size = 2,\n",
    "    save_steps = 1000,\n",
    "    save_total_limit = 2,\n",
    "    logging_steps=1,\n",
    "    report_to='none'    \n",
    ")\n",
    "# 트레인\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm=False)\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    train_dataset = tokenized_dataset,\n",
    "    args = train_args,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = data_collator)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f12a962-a3f4-443f-90b8-78c822b01229",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(30080, 4096)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (query_key_value): Linear4bit(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear4bit(in_features=4096, out_features=4096, bias=True)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear4bit(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear4bit(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "  )\n",
       "  (embed_out): Linear(in_features=4096, out_features=30080, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 구조 확인(필요시)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5be3d32d-aa65-4d63-879e-b28b6a210573",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "### instruction:한국 보이 그룹이 세계적으로 인기를 얻는 이유는 무엇인가요?\n",
      "\n",
      "### 정답:한국의 대중음악은 K-Pop으로 불리며, 그 중에서도 보이 그룹이 큰 인기를 얻고 있습니다. 이유는 다양한 음악 장르에서 다양한 매력을 지니고 있기 때문입니다. 또한, 한국의 음반 시장은 세계적인 음반 시장 중 하나이기 때문에 외국 유명 가수들이 진출해 자신의 음악을 홍보하는 기회가 많습니다. 이와 함께, K-Pop 문화가 이미 세계적으로 자리 잡았기 때문에, 해당 문화를 이해하고 즐기는 외국인들이 많아져 더 인기가 높아졌습니다. \n"
     ]
    }
   ],
   "source": [
    "# 6. 추론\n",
    "instruction = '한국 보이 그룹이 세계적으로 인기를 얻는 이유는 무엇인가요?'\n",
    "input_text = f'### instruction:{instruction}\\n\\n### 정답:'\n",
    "input_ids = tokenizer.encode(input_text,return_tensors='pt').to('cuda')\n",
    "print(type(input_ids))\n",
    "output =  model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature = 0.7,   \n",
    "    top_p=0.9,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "print(tokenizer.decode(output[0],skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e619ff-a241-4bdd-a779-6b01f5719f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f560e6f-e28e-4b30-8969-b6577f1c3f0f",
   "metadata": {},
   "source": [
    "**RAG 구성**\n",
    "```\n",
    "Retiever : 외부문서에서 관련 정보를 찾아주는 모듈\n",
    "Embedding Model(한국어 지원 멀티타스트계열)  ko multitask\n",
    "Vector Store(FAISS) : 임베딩된 문서를 저장 및 검색\n",
    "LLM (koAlpaca를 기반으로 QLoRa 튜닝된 모델)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e80ce679-cb29-4247-87d1-b3da527fc131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71877c69-650d-4ed9-adc3-c01a989f10b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
